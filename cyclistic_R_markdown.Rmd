---
title: "Cyclistic Bike-Share Analysis:<br>Usage Patterns of Non-members and Members"
subtitle: "Capstone Project for Google Data Analytics Certificate"
author: "Brian Cox"
date: "March 5, 2024"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 3
    number_sections: false
---
===============================================================================
\

# Overview

---

### Background

This data analysis is a capstone project for the Google Data Analytics Certificate.

Cyclistic is a fictional bikeshare company in Chicago, IL, USA.  In this scenario, the company is conducting a campaign to convert its non-member users into annual members.  To that end, I am assigned to reveal insights into how non-members use the service compared to how members use it.

### Data

At my disposal is a dataset of all Cyclistic trips taken in 2023, containing 12 CSV files (one for each month).  Each of the approximately 5.7 million records is an observation of one trip.  Original data available [here][box source data]

The data contain the following variables (see appendix for schema):

1.	Ride ID: primary key
2.	User membership status: member or “casual” (non-member)
3.	Type of bicycle used: classic, electric, or docked
4.	Beginning and ending date-times of the trip, with precision in seconds
5.	Beginning and ending coordinates (latitude and longitude) of the trip, with precision to five decimal places (roughly 4 feet)
6.	Starting and ending station ID’s and station names

#### Limitations

Notably, the data does not contain user identification.  This shortcoming is significantly limiting, because we don’t know how many unique users there were, how many different trips were taken by individual users, or what the usage patterns were for individual users.

### Documents

I used R (with R Studio) and SQL (with BigQuery) to clean and transform the data, and to perform most of the analysis.  I used Tableau and Excel for some analysis, and Tableau for the final data visualization.

The resulting files ([Github repo][github cyclistic repo] | [Box parent folder][box cyclistic folder]) include:\

- R markdown - [Github][github r markdown] | [Box][box r markdown]
- R script - [Github][github r script] | [Box][box r script] 
- SQL script - [Github][github sql script] | [BigQuery][bigquery script] | [Box]
- Tableau story - [Tableau Public][tableau static story]
\
\ 

# Data cleaning and Transformation

---

## Prepare environment and data


##### _Load packages_

```{r set-environment, message = FALSE, warning = FALSE}

library(tidyverse)

library(data.table)

library(kableExtra)
```
\

##### _Set some preferred defaults using functions and options_

```{r set-defaults}

options(scipen = 9)

cable <- function(x) {
        kbl(x, format.args = list(big.mark = ",")) %>%
        kable_styling("hover", full_width = FALSE, position = "left",
                      font_size = 12)
}

theme_set(theme_minimal())

theme_update(legend.position = "none", plot.margin = margin(20,5,20,5))

blues <- c(member = "lightblue", casual = "navy")

month_labels <- c("Feb", "Apr", "Jun", "Aug", "Oct", "Dec")
```
\

##### _Compile monthly files into one yearly table_

```{r compile-data}

setwd("./data/monthly")

file_list <- list.files()

file_list

year_data <-
        file_list %>% 
        lapply(function(x) fread(x)) %>% 
        rbindlist()

setwd("../..")
```
\

##### _Preview compiled data_

```{r preview-data}

str(year_data)

summary(year_data)
```
\

## Identify and address invalid or messy data
\
A few things stand out in the summary:

- The names of the columns "started_at" and "ended_at" make it unclear whether they refer to time or geography
- There are NA's in the end coordinates
- There are zero values in the end coordinates\
\

##### _Rename ambiguously named datetime columns_

```{r rename-columns}

colnames(year_data)[3] <- "time_start"

colnames(year_data)[4] <- "time_end"
```
\

##### _Identify and investigate NA's_

```{r quantify-na}

colSums(is.na(year_data)) %>%
        kbl(col.names = NULL, format.args = list(big.mark = ",")) %>%
        kable_styling("hover", full_width = FALSE, position = "left",
                      font_size = 12)
```

```{r evaluate-na-coords}

number_na_end_coords <-
        nrow(year_data[is.na(end_lng) | is.na(end_lat), ])

percent_na_end_coords <-
        number_na_end_coords / nrow(year_data) * 100

cat(c("Records with missing end coordinates are",
      round(percent_na_end_coords, 2),
      "% of the total records"))
```
\
I can get rid of the records with missing end coordinates because

- they are a very small percentage of the records, and
- they are not an important subset of the data\
\
   
##### _Remove NA's from dataset_

```{r remove-na-coords}

year_data <-
        year_data %>% 
        filter(!is.na(end_lat) & !is.na(end_lng))
```
\

##### _Quantify and investigate zero coordinates_

```{r quantify-zero-coords}

number_zero_end_coords <-
        nrow(year_data[end_lng == 0 | end_lat == 0, ])

cat(c("There are",
      number_zero_end_coords,
      "records with zero for an ending longitude or latitude"))

year_data[end_lng == 0 | end_lat == 0, ] %>% cable()
```
\

There are 3 records with zero for an ending longitude or latitude. All 3 have the coordinates (0,0) which is in the ocean off of Ghana.\

I can remove those records but I notice that two of them are labeled in the station names or id's as "Test."  First I'll look for other records with "Test" labels\
\

##### _Identify and investigate stations labeled "test"_

```{r identify-test-stations}

tests <-
        year_data[grepl("test", year_data$start_station_name,
                        ignore.case = TRUE) |
                  grepl("test", year_data$end_station_name,
                        ignore.case = TRUE) |
                  grepl("test", year_data$start_station_id,
                        ignore.case = TRUE) |
                  grepl("test", year_data$end_station_id,
                        ignore.case = TRUE), ]

nrow(tests)

view(tests)
```
\
Those all look like tests and there are only 106 additional, so I'll remove them too.\
\

##### _Remove zero coordinates and tests from dataset_

```{r remove-zero-coords-and-tests}

year_data <-
        year_data %>% 
        filter(end_lat != 0 & end_lng !=0,
               !grepl("test", start_station_name, ignore.case = TRUE),
               !grepl("test", end_station_name, ignore.case = TRUE),
               !grepl("test", start_station_id, ignore.case = TRUE),
               !grepl("test", end_station_id, ignore.case = TRUE))
```
\

##### _Verify uniqueness of primary key values_

```{r verify-unique-ride-ids}

length(unique(year_data$ride_id)) == nrow(year_data)
```
\

##### _Look for invalid values in character columns with low cardinality_

```{r validate-character-columns}

unique(year_data$rideable_type)

unique(year_data$member_casual)
```
\

##### _Identify empty strings in each character column_

```{r quantify-empty-strings}

year_data %>%
        select_if(is.character) %>%
        sapply(function(x) sum(x == "")) %>% 
        kbl(col.names = NULL, format.args = list(big.mark = ",")) %>%
        kable_styling("hover", full_width = FALSE, position = "left",
                      font_size = 12)
```
\

##### _Investigate empty strings in station id's and station names_

```{r quantify-empty-station-ids}

percent_empty_start_id <-
        round(sum(year_data$start_station_id == "") / nrow(year_data) * 100, 2)

percent_empty_end_id <- 
        round(sum(year_data$end_station_id == "") / nrow(year_data) * 100, 2)
        
cat(paste(percent_empty_start_id,
      "% of the start station ids are empty, and",
    percent_empty_end_id, 
      "% of the end station ids are empty"))
```
\
That's too many to throw away, and those fields are just labels anyway, so the fact that they're missing doesn't compromise the data.

Since the station ID's and names are just labels, I can replace the empties with arbitrary values without changing the data substantively\

- For empty station id's, create a new station id by concatenating their latitude & longitude
- For empty station names, create new station names which are equal to the station id's\
\

##### _Substitute in arbitrary values for empty station id's and names_

```{r replace-empty-station-labels}

year_data <-
        year_data %>% 
        mutate(
                start_station_id = case_when(
                        start_station_id == '' ~ paste(start_lat,start_lng),
                        .default = as.character(start_station_id)),
                end_station_id = case_when(
                        end_station_id == '' ~ paste(end_lat,end_lng),
                        .default = as.character(end_station_id))
        )

year_data <- 
        year_data %>% 
        mutate(
                start_station_name = case_when(
                        start_station_name == '' ~ start_station_id,
                        .default = as.character(start_station_name)),
                end_station_name = case_when(
                        end_station_name == '' ~ end_station_id,
                        .default = as.character(end_station_name))
        )
```
\

#### Investigate validity of datetime columns
\
The summary above showed that the values in each datetime column are valid on their own.\
But I created and investigated a duration column to check out the relationship between the two.\
\

##### _Create duration column and look for outliers and strange values_

```{r create-duration-column}

year_data$duration_mins <-
        as.numeric(difftime(year_data$time_end,
                            year_data$time_start, units = "mins"))

summary(year_data$duration_mins)
```

```{r identify-strange-durations}

na_durations <- sum(is.na(year_data$duration_mins))

negative_durations <- sum(year_data$duration_mins < 0)

zero_durations <- sum(year_data$duration_mins == 0)

dayplus_durations <- sum(year_data$duration_mins >= 1440)

strange_duration_report <- data.table(
        na_durations, negative_durations,
        zero_durations, dayplus_durations
)

percent_strange_durations <-
        sum(na_durations, negative_durations, zero_durations,
        dayplus_durations) / nrow(year_data) * 100

strange_duration_report %>% cable()

cat("records with strange durations are",
    round(percent_strange_durations, 2), "% of the total records")
```
\
I can remove the records with strange duration values because

- they are a very small percentage of the records, and
- they are not an important subset of the data\
\

##### _Remove records with strange duration values_

```{r remove-strange-durations}

year_data <-
        year_data[year_data$duration_mins > 0 &
        year_data$duration_mins < 1440, ]
```
\

##### _Re-summarize duration column to scan for remaining anomalies_

```{r validate-duration-column}

na_durations <- sum(is.na(year_data$duration_mins))

negative_durations <- sum(year_data$duration_mins < 0)

zero_durations <- sum(year_data$duration_mins == 0)

dayplus_durations <- sum(year_data$duration_mins >= 1440)

min_duration <- min(year_data$duration_mins) %>% round(4)

avg_duration <- mean(year_data$duration_mins) %>% round(2)

median_duration <- median(year_data$duration_mins) %>% round(2)

percentile_99.9 <- quantile(year_data$duration_mins, probs = 0.999) %>% round(1)

max_duration <- max(year_data$duration_mins) %>% round(1)

clean_duration_report <-
        data.table(na_durations, negative_durations, zero_durations,
                   dayplus_durations, min_duration, median_duration,
                   avg_duration, percentile_99.9, max_duration)

clean_duration_report %>% cable()

```
\

##### _Plot duration distribution to check if it generally makes sense_

```{r plot-duration, warning=FALSE}

ggplot(year_data, aes(x = duration_mins)) +
        geom_histogram(binwidth = 15) +
        xlim(0, 1500)

ggplot(year_data, aes(x = duration_mins, fill = member_casual)) +
        geom_histogram(binwidth = 5) +
        xlim(0, 100) +
        scale_fill_manual(values = blues) +
        facet_wrap(member_casual ~ .)
```
\
\

## Sample the data

The data is too big for the limited amount of RAM my laptop has.

Taking a 10% random sample will provide

- 99.99% confidence level, with
- less than 0.25% margin of error

Set seed first to ensure reproducibility\

**This sample will be the dataset used for the rest of the analysis**

```{r sample-data}

set.seed(0)

smp <- slice_sample(year_data, prop = 0.1)
```
\

## Export data and clean up environment
\

##### _Export .csv files for use in other tools_

eval is set to FALSE so no data is actually written to disk when knitting for review.

To keep the dataset tidy, the duration column is excluded from the export because it is a calculated, added field.

```{r export-sampled-table, eval = FALSE}

fwrite(smp[!"duration_mins"],
       "./data/yearly/sampled_yearly_data.csv")

fwrite(year_data[!"duration_mins"],
       "./data/yearly/clean_whole_year.csv")
```
\

##### _Clear unneeded objects from environment_

```{r clear-environment}

rm(
        file_list, tests,
        number_na_end_coords, percent_na_end_coords, number_zero_end_coords,
        na_durations, negative_durations, zero_durations, dayplus_durations,
        strange_duration_report, percent_strange_durations, min_duration,
        avg_duration, median_duration, percentile_99.9, max_duration,
        clean_duration_report, percent_empty_start_id, percent_empty_end_id,
        year_data
)
```
\

## Add calculated fields for use in analysis

Day Type

- Weekend: Saturday and Sunday
- Shoulder Weekday: Monday and Friday
- Middle Weekday: Tuesday, Wednesday, and Thursday

Trip Type

- Round Trip: start and end coordinates are the same
- One Way: start and end coordinates are different

Hour

- hour of the day the ride started

Month

- month of the year the ride started

```{r add-calculated-fields}

smp <- smp %>% 
        mutate(day_type =
                       case_when(wday(time_start) %in% c(1, 7) ~ "Weekend",
                                 wday(time_start) %in% c(2, 6) ~
                                         "Shoulder Weekday",
                                 wday(time_start) %in% 3:5 ~ "Middle Weekday"),
               trip_type =
                       case_when(paste(start_lat, start_lng) ==
                                         paste(end_lat, end_lng) ~ "Round Trip",
                                 .default = "One Way"),
               hour_start = hour(time_start),
               month_start = month(time_start)
        )
```
\

##### _Check newly created variables for validity and reasonableness_

```{r validate-calculated-fields}

table(smp$member_casual, smp$day_type) %>% cable()

table(smp$member_casual, smp$trip_type) %>% cable()

table(smp$member_casual, smp$hour_start) %>% cable()

table(smp$member_casual, smp$month_start) %>% cable()
```
\

#### Add geographically calculated fields
\

I used BigQuery to calculate the distance and direction of each ride, using the following query, because the same computations in R were too memory-intensive for my laptop, then exported the results.

- Distance: in miles between start and end coordinates
- Direction: cardinal direction from start to end, in integer degrees
\
\

##### _Calculate distance and direction_

```{sql, eval = FALSE, engine = "sql"}

DROP TABLE IF EXISTS cyclistic.geo;
CREATE TABLE cyclistic.geo AS
    SELECT
        ride_id,
        (ST_DISTANCE(ST_GEOGPOINT(end_lng, end_lat),
                ST_GEOGPOINT(start_lng, start_lat)))
                * 0.0006213712 ## convert meters to miles
                AS distance_miles,
        CAST(ST_AZIMUTH(ST_GEOGPOINT(start_lng, start_lat),
                ST_GEOGPOINT(end_lng, end_lat))
                * 57.29578 AS INT64) ## convert radians to degrees
                AS direction
    FROM cyclistic.smp
    WHERE trip_type = 'One Way';
```
\

##### _Read in geographically calculated data_

```{r read-geo-data}

geo <- fread("./data/yearly/geo_calc_vars.csv")
```
\
\

# Exploratory analysis

---

For brevity I have only included selected examples of the exploratory analysis in this file.

Because I did the final presentation in Tableau, I've given the graphics below enough formatting to be clear, but not as much as for a final presentation.

## Time clustering

```{r time-clustering}

ggplot(smp, aes(day_type, after_stat(prop), group = member_casual,
                fill = member_casual,
                label = paste(round(after_stat(prop)*100),"%"))) +
        geom_bar() +
        labs(title = "Percent of Rides by Day Type",
             subtitle = "Members rode more midweek, non-members weekends") +
        geom_text(stat = "count", color = "white", nudge_y = -0.05) +
        scale_y_continuous(label = scales::percent) +
        theme(axis.text.y=element_blank()) +
        scale_fill_manual(values = blues) +
        facet_grid(vars(member_casual))

ggplot(smp, aes(hour_start, after_stat(prop), fill = member_casual)) +
        geom_bar() +
        labs(title = "Percent of Rides by Hour and Day Type",
             subtitle = "Members had a bigger spike during the morning commute") +
        scale_y_continuous(label = scales::percent) +
        scale_fill_manual(values = blues) +
        facet_grid(vars(member_casual), vars(day_type))

ggplot(smp, aes(month_start, after_stat(prop), fill = member_casual)) +
        geom_bar() +
        labs(title = "Percent of Rides by Month and Day Type",
             subtitle = "Non-members' usage was more seasonal") +
        scale_x_continuous(breaks = c(2, 4, 6, 8, 10, 12),
                           labels = month_labels) +
        scale_y_continuous(label = scales::percent) +
        scale_fill_manual(values = blues) +
        facet_grid(vars(member_casual), vars(day_type))
```
\
These differences, when combined with location data (maps and analysis are in the Tableau story) and the fact that non-members tend to take longer, slower rides (see below), suggest that non-members were more likely to use the service for recreation, while members were more likely to commute.  If the company could add or modify memberships to make them more attractive for recreational use, more non-members may convert.

However, the data also show that non-members did a lot of commuting as well as recreating.  Therefore the company should also seek conversions among commuting non-members.  Acquiring and analyzing ride data that includes unique user id (even if anonymized or de-identified) could help uncover reasons why non-member commuters haven't become members. For example, were they commuting too infrequently or irregularly to justify membership cost? 

## Direction

```{r direction}

dir_mwd_morning <- smp %>%
        right_join(geo, by = join_by(ride_id)) %>% 
        filter(day_type == 'Middle Weekday',
               hour_start %in% 5:8,
               distance_miles > 1)

dir_mwd_evening <- smp %>%
        right_join(geo, by = join_by(ride_id)) %>% 
        filter(day_type == 'Middle Weekday',
               hour_start %in% 15:18,
               distance_miles > 1)

ggplot(dir_mwd_morning, aes(direction, after_stat(prop), group = member_casual,
                            fill = member_casual)) +
        geom_bar() +
        labs(title = "Direction of Rides During Midweek Morning Commute") +
        scale_x_continuous(breaks = c(0, 90, 180, 270, 360)) +
        scale_y_continuous(label = scales::percent) +
        scale_fill_manual(values = blues) +
        facet_grid(vars(member_casual))

ggplot(dir_mwd_evening, aes(direction, after_stat(prop), group = member_casual,
                            fill = member_casual)) +
        geom_bar() +
        labs(title = "Direction of Rides During Midweek Evening Commute") +
        scale_x_continuous(breaks = c(0, 90, 180, 270, 360)) +
        scale_y_continuous(label = scales::percent) +
        scale_fill_manual(values = blues) +
        facet_grid(vars(member_casual))
```
\
The overall NNW - SSE pattern is interesting, if unsurprising given the orientation of the the Chicago lakefront. The prevalence of SSE rides in the morning and NNW rides in the evening is also interesting. But there is not a meaningful difference between members and non-members, so this measure did not make it to the final analysis.\ 
\

## Distance, Duration, and Speed

```{r distance-duration-speed, warning = FALSE, message = FALSE}

smp %>% right_join(geo, by = join_by(ride_id)) %>%
        filter(rideable_type != 'docked_bike') %>%
        group_by(member_casual) %>% 
        summarise(median_duration_mins = median(duration_mins) %>% round(1),
                  median_distance_mi = median(distance_miles) %>% round(2),
                  median_speed_mph = median(distance_miles /
                                     (duration_mins / 60)) %>% round(1)) %>% 
        cable()

smp %>% right_join(geo, by = join_by(ride_id)) %>%
        filter(rideable_type != 'docked_bike',
               day_type != 'Shoulder Weekday') %>%
        group_by(day_type, member_casual) %>% 
        summarise(median_duration_mins = median(duration_mins) %>% round(1),
                  median_distance_mi = median(distance_miles) %>% round(2),
                  median_speed_mph = median(distance_miles /
                                     (duration_mins / 60)) %>% round(1)) %>% 
        kbl() %>%
        kable_styling("striped", full_width = FALSE, position = "left",
                      font_size = 12)
```
\

##### Distance

```{r distance, warning = FALSE}

quantile(geo$distance_miles, 0.9) %>% round(2) %>%
        kbl(col.names = NULL) %>%
        kable_styling(full_width = FALSE, position = "left",
                      font_size = 12)

dist_box <- smp %>%
        select(ride_id, member_casual, day_type, rideable_type) %>%
        right_join(geo, by = join_by(ride_id)) %>%
        filter(distance_miles > 0 & distance_miles <= 2.87,
               day_type != 'Shoulder Weekday',
               rideable_type != 'docked_bike'
        )

ggplot(dist_box, aes(rideable_type, distance_miles)) +
        geom_boxplot() +
        labs(title = "Median Distance of Rides by Bike Type and Day Type",
             subtitle = "Members used electric bikes for longer distances, but non-members did not") +
        facet_grid(vars(member_casual), vars(day_type))
```
\
This difference may show that when commuting, members were more strategic about using electric bikes for longer rides to save time, and regular bikes for shorter rides to save money.  If the company could educate commuting non-members about strategies like this, they may be more likely to convert.

On the other hand, some of this difference may be that because non-members were more likely to use the service for recreation, they may be have chosen regular bikes more because they weren't trying to save time. 
\
\

##### Duration

```{r duration}

quantile(smp$duration_mins, 0.9) %>% round(2) %>%
        kbl(col.names = NULL) %>%
        kable_styling(full_width = FALSE, position = "left",
                      font_size = 12)

dur_box <- smp %>% 
        filter(duration_mins > 0 & duration_mins <= 29.03,
               day_type != "Shoulder Weekday")

ggplot(dur_box, aes(member_casual, duration_mins)) +
        geom_boxplot() +
        labs(title = "Median Duration of Rides by Day Type",
             subtitle = "Non-members rode for longer times, especially on weekends") +
        facet_grid(vars(day_type))

ggplot(dur_box, aes(member_casual, duration_mins)) +
        geom_boxplot() +
        labs(title = "Median Duration of Rides by Day Type and Month",
             subtitle = "The biggest difference was in the summer") +
        scale_x_discrete(labels = c("c", "m")) +
        facet_grid(vars(day_type), vars(month_start))
```
\
\

# Appendix

---

### Source data schema

```{r schema-table, echo = FALSE, message = FALSE, warning = FALSE}

schema <- data.table(
        Field = c("ride_id", "rideable_type", "started_at", "ended_at",
                       "start_station_name", "start_station_id",
                       "end_station_name", "end_station_id",
                       "start_lat", "start_lng", "end_lat", "end_lng",
                       "member_casual"),
        Type = c("character", "character", "datetime", "datetime",
                      "character", "character", "character", "character",
                      "numeric", "numeric", "numeric", "numeric",
                      "character"),
        Notes = c("Primary Key", "", "","", "", "", "", "", "", "", "", "",
                  ""))

schema %>% kbl() %>%
        kable_styling("hover", position = "left", full_width = FALSE,
                      font_size = 13) %>%
        column_spec(1, width = "12em") %>% 
        column_spec(2, width = "8em")
```

        
### Links

##### Project

- [Github](https://github.com/briancox-c/Cyclistic) | All code 
- [Box](https://app.box.com/s/ohes059e27dnedakt147zcyayikpggyv) | All code and source data
- [BigQuery](https://console.cloud.google.com/bigquery?sq=975725981649:07826d28c3dc41a789ad77b36d5f6b5a) | SQL script
- [Tableau Public](https://public.tableau.com/views/Cyclistic_17096823715860/Cyclistic?:language=en-US&:sid=&:display_count=n&:origin=viz_share_link) | Tableau story

##### Personal

- [LinkedIn](https://www.linkedin.com/in/brian-cox-6905a6256/)
- [Coursera](https://www.coursera.org/user/1fcea3b66e06e9b1d206bc66e9aa4039)
- [Github](https://github.com/briancox-c)
- [Tableau Public](https://public.tableau.com/app/profile/brian.cox3159/vizzes)

Link references

[github cyclistic repo](https://github.com/briancox-c/Cyclistic)
[github r script](https://github.com/briancox-c/Cyclistic/blob/main/cyclistic_R_script.R)
[github r markdown]
[github sql script](https://github.com/briancox-c/Cyclistic/blob/main/cyclistic_SQL.sql)

[box cyclistic folder](https://app.box.com/s/tsk5a727knki8srve95xdrx6ckjxr97d)
[box source data](https://app.box.com/s/pmz7b6zl4h5n0exnawnwxhpvkuaw0hou)
[box r script](https://app.box.com/s/0jmubg01c2p8eoinjtzaz0iq45vcutld)
[box r markdown]
[box sql script](https://app.box.com/s/im7wen2y1jjdebrx924ahdgp0gell4rs)

[tableau static story]

[bigquery script](https://console.cloud.google.com/bigquery?sq=975725981649:07826d28c3dc41a789ad77b36d5f6b5a)

